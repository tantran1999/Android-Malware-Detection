import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
from keras.layers import Input, Dense
from keras.models import Model, load_model
from dbn.tensorflow import SupervisedDBNClassification
from dbn.models import UnsupervisedDBN
from sklearn.svm import SVC, LinearSVC, NuSVR
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from imports import *

class PreTest():
     def __init__(self):
         self.dataBenign = {"permissions":[], "isValidAPK":[], "services":[], "receivers":[] }
         self.dataMalign = {"permissions":[], "isValidAPK":[], "services":[], "receivers":[] }

         # Placeholders for the massive vocabulary that will be generated during pre processing.
         self.vocabPerm = list()
         self.vocabServ = list()
         self.vocabRecv = list()
         if LOAD_DATA == True:
            """
                Bool to decide whether to load data dictionaries previously pickled.
            """
            print("Loading data..")
            f = open("pickled/dataDictBenign.pkl", "rb")
            self.dataBenign = pickle.load(f)
            f.close()

            f = open("pickled/dataDictMalign.pkl", "rb")
            self.dataMalign = pickle.load(f)
            f.close()

            f = open("pickled/vocabPerm.pkl", "rb")
            self.vocabPerm = pickle.load(f)
            f.close()
            f = open("pickled/vocabServ.pkl", "rb")
            self.vocabServ = pickle.load(f)
            f.close()

            f = open("pickled/vocabRecv.pkl", "rb")
            self.vocabRecv = pickle.load(f)
            f.close()

            f = open("pickled/vocabLen.pkl", "rb")
            self.vocabLengths = pickle.load(f)
            f.close()
     def makeHotVector(self, vec, len):
         hotVec = np.zeros(len, dtype='int')
         hotVec[vec] = 1
         return hotVec